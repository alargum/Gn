{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d35e07b1-2066-4156-8fdd-04e12b58aae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b106/anaconda3/envs/pytorch-gpu/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ee628b-d7bd-40bf-ba36-b80995bc7a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d019a399-f199-4b39-9543-96f8ea5a0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files\n",
    "train_df = pd.read_csv('train_covid.csv')\n",
    "test_df = pd.read_csv('test_covid.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5866ac23-3bf3-4f97-83f1-421933acd053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing \n",
    "# Separate features and target variable from training data\n",
    "X = train_df.drop(columns=['Prognosis'])\n",
    "y = train_df['Prognosis']\n",
    "\n",
    "# Convert target variable to binary\n",
    "y = y.map({'MILD': 0, 'SEVERE': 1})\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "categorical_cols = ['Hospital', 'Sex']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols + ['Image']]\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3268cd70-9cdd-4668-b809-8223cbb7c0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 0/29, Train Loss: 0.7264, Train Acc: 0.5000, Val Loss: 0.6794, Val Acc: 0.5894\n",
      "Epoch 1/29, Train Loss: 0.6992, Train Acc: 0.5364, Val Loss: 0.6459, Val Acc: 0.6522\n",
      "Epoch 2/29, Train Loss: 0.6374, Train Acc: 0.6723, Val Loss: 0.6235, Val Acc: 0.6425\n",
      "Epoch 3/29, Train Loss: 0.5853, Train Acc: 0.7075, Val Loss: 0.5827, Val Acc: 0.6908\n",
      "Epoch 4/29, Train Loss: 0.5570, Train Acc: 0.7124, Val Loss: 0.5866, Val Acc: 0.7053\n",
      "Epoch 5/29, Train Loss: 0.5442, Train Acc: 0.7391, Val Loss: 0.5830, Val Acc: 0.7053\n",
      "Epoch 6/29, Train Loss: 0.5170, Train Acc: 0.7561, Val Loss: 0.5184, Val Acc: 0.7150\n",
      "Epoch 7/29, Train Loss: 0.4914, Train Acc: 0.7779, Val Loss: 0.5159, Val Acc: 0.7246\n",
      "Epoch 8/29, Train Loss: 0.4874, Train Acc: 0.7718, Val Loss: 0.4992, Val Acc: 0.7295\n",
      "Epoch 9/29, Train Loss: 0.4763, Train Acc: 0.7731, Val Loss: 0.5544, Val Acc: 0.7246\n",
      "Epoch 10/29, Train Loss: 0.4771, Train Acc: 0.7670, Val Loss: 0.4940, Val Acc: 0.7246\n",
      "Epoch 11/29, Train Loss: 0.4898, Train Acc: 0.7755, Val Loss: 0.5076, Val Acc: 0.7488\n",
      "Epoch 12/29, Train Loss: 0.4585, Train Acc: 0.7791, Val Loss: 0.4966, Val Acc: 0.7246\n",
      "Epoch 13/29, Train Loss: 0.4324, Train Acc: 0.7998, Val Loss: 0.5149, Val Acc: 0.7440\n",
      "Epoch 14/29, Train Loss: 0.4321, Train Acc: 0.8046, Val Loss: 0.5199, Val Acc: 0.7343\n",
      "Epoch 15/29, Train Loss: 0.4515, Train Acc: 0.7852, Val Loss: 0.5030, Val Acc: 0.7440\n",
      "Epoch 16/29, Train Loss: 0.3999, Train Acc: 0.8167, Val Loss: 0.5107, Val Acc: 0.7391\n",
      "Epoch 17/29, Train Loss: 0.4113, Train Acc: 0.8265, Val Loss: 0.5167, Val Acc: 0.7536\n",
      "Epoch 18/29, Train Loss: 0.3919, Train Acc: 0.8386, Val Loss: 0.5179, Val Acc: 0.7391\n",
      "Epoch 19/29, Train Loss: 0.3873, Train Acc: 0.8313, Val Loss: 0.5566, Val Acc: 0.7150\n",
      "Epoch 20/29, Train Loss: 0.3911, Train Acc: 0.8301, Val Loss: 0.5227, Val Acc: 0.7488\n",
      "Epoch 21/29, Train Loss: 0.3879, Train Acc: 0.8119, Val Loss: 0.5219, Val Acc: 0.7150\n",
      "Epoch 22/29, Train Loss: 0.3436, Train Acc: 0.8519, Val Loss: 0.5319, Val Acc: 0.7343\n",
      "Epoch 23/29, Train Loss: 0.3433, Train Acc: 0.8629, Val Loss: 0.5248, Val Acc: 0.7585\n",
      "Epoch 24/29, Train Loss: 0.3382, Train Acc: 0.8519, Val Loss: 0.5249, Val Acc: 0.7246\n",
      "Epoch 25/29, Train Loss: 0.3554, Train Acc: 0.8556, Val Loss: 0.5292, Val Acc: 0.7391\n",
      "Epoch 26/29, Train Loss: 0.3718, Train Acc: 0.8337, Val Loss: 0.5232, Val Acc: 0.7391\n",
      "Epoch 27/29, Train Loss: 0.3315, Train Acc: 0.8459, Val Loss: 0.5237, Val Acc: 0.7391\n",
      "Epoch 28/29, Train Loss: 0.3125, Train Acc: 0.8677, Val Loss: 0.5215, Val Acc: 0.7295\n",
      "Epoch 29/29, Train Loss: 0.3281, Train Acc: 0.8677, Val Loss: 0.5233, Val Acc: 0.7198\n",
      "Fold 1 Balanced Accuracy: 0.7119932432432432\n",
      "Fold 2/5\n",
      "Epoch 0/29, Train Loss: 0.7324, Train Acc: 0.4909, Val Loss: 0.6837, Val Acc: 0.5631\n",
      "Epoch 1/29, Train Loss: 0.6903, Train Acc: 0.5539, Val Loss: 0.6399, Val Acc: 0.6505\n",
      "Epoch 2/29, Train Loss: 0.6452, Train Acc: 0.6339, Val Loss: 0.6062, Val Acc: 0.6699\n",
      "Epoch 3/29, Train Loss: 0.5839, Train Acc: 0.7164, Val Loss: 0.6107, Val Acc: 0.6602\n",
      "Epoch 4/29, Train Loss: 0.5633, Train Acc: 0.7164, Val Loss: 0.5769, Val Acc: 0.6796\n",
      "Epoch 5/29, Train Loss: 0.5363, Train Acc: 0.7467, Val Loss: 0.5629, Val Acc: 0.7087\n",
      "Epoch 6/29, Train Loss: 0.5252, Train Acc: 0.7455, Val Loss: 0.5417, Val Acc: 0.7330\n",
      "Epoch 7/29, Train Loss: 0.5068, Train Acc: 0.7612, Val Loss: 0.5423, Val Acc: 0.7039\n",
      "Epoch 8/29, Train Loss: 0.5157, Train Acc: 0.7733, Val Loss: 0.5081, Val Acc: 0.7476\n",
      "Epoch 9/29, Train Loss: 0.4866, Train Acc: 0.7685, Val Loss: 0.5115, Val Acc: 0.7524\n",
      "Epoch 10/29, Train Loss: 0.4548, Train Acc: 0.7745, Val Loss: 0.5108, Val Acc: 0.7136\n",
      "Epoch 11/29, Train Loss: 0.4464, Train Acc: 0.7806, Val Loss: 0.5385, Val Acc: 0.7427\n",
      "Epoch 12/29, Train Loss: 0.4453, Train Acc: 0.7964, Val Loss: 0.5116, Val Acc: 0.7379\n",
      "Epoch 13/29, Train Loss: 0.4174, Train Acc: 0.8194, Val Loss: 0.5195, Val Acc: 0.7427\n",
      "Epoch 14/29, Train Loss: 0.4313, Train Acc: 0.8097, Val Loss: 0.5055, Val Acc: 0.7670\n",
      "Epoch 15/29, Train Loss: 0.4351, Train Acc: 0.8012, Val Loss: 0.5063, Val Acc: 0.7330\n",
      "Epoch 16/29, Train Loss: 0.3748, Train Acc: 0.8388, Val Loss: 0.5023, Val Acc: 0.7718\n",
      "Epoch 17/29, Train Loss: 0.4106, Train Acc: 0.8109, Val Loss: 0.5176, Val Acc: 0.7621\n",
      "Epoch 18/29, Train Loss: 0.3914, Train Acc: 0.8230, Val Loss: 0.5040, Val Acc: 0.7864\n",
      "Epoch 19/29, Train Loss: 0.3638, Train Acc: 0.8218, Val Loss: 0.5343, Val Acc: 0.7476\n",
      "Epoch 20/29, Train Loss: 0.3914, Train Acc: 0.8182, Val Loss: 0.5297, Val Acc: 0.7524\n",
      "Epoch 21/29, Train Loss: 0.3641, Train Acc: 0.8279, Val Loss: 0.5212, Val Acc: 0.7670\n",
      "Epoch 22/29, Train Loss: 0.3423, Train Acc: 0.8545, Val Loss: 0.5475, Val Acc: 0.7427\n",
      "Epoch 23/29, Train Loss: 0.3821, Train Acc: 0.8315, Val Loss: 0.5353, Val Acc: 0.7573\n",
      "Epoch 24/29, Train Loss: 0.3607, Train Acc: 0.8473, Val Loss: 0.5340, Val Acc: 0.7476\n",
      "Epoch 25/29, Train Loss: 0.3517, Train Acc: 0.8339, Val Loss: 0.5366, Val Acc: 0.7573\n",
      "Epoch 26/29, Train Loss: 0.3591, Train Acc: 0.8424, Val Loss: 0.5337, Val Acc: 0.7476\n",
      "Epoch 27/29, Train Loss: 0.3502, Train Acc: 0.8364, Val Loss: 0.5275, Val Acc: 0.7476\n",
      "Epoch 28/29, Train Loss: 0.3159, Train Acc: 0.8691, Val Loss: 0.5312, Val Acc: 0.7427\n",
      "Epoch 29/29, Train Loss: 0.3492, Train Acc: 0.8582, Val Loss: 0.5320, Val Acc: 0.7524\n",
      "Fold 2 Balanced Accuracy: 0.7482693219535326\n",
      "Fold 3/5\n",
      "Epoch 0/29, Train Loss: 0.7259, Train Acc: 0.4970, Val Loss: 0.6757, Val Acc: 0.6845\n",
      "Epoch 1/29, Train Loss: 0.7007, Train Acc: 0.5248, Val Loss: 0.6390, Val Acc: 0.7136\n",
      "Epoch 2/29, Train Loss: 0.6613, Train Acc: 0.5903, Val Loss: 0.5923, Val Acc: 0.7427\n",
      "Epoch 3/29, Train Loss: 0.5870, Train Acc: 0.6958, Val Loss: 0.5554, Val Acc: 0.7282\n",
      "Epoch 4/29, Train Loss: 0.5763, Train Acc: 0.6970, Val Loss: 0.5446, Val Acc: 0.6893\n",
      "Epoch 5/29, Train Loss: 0.5519, Train Acc: 0.7273, Val Loss: 0.5453, Val Acc: 0.7573\n",
      "Epoch 6/29, Train Loss: 0.5404, Train Acc: 0.7358, Val Loss: 0.5367, Val Acc: 0.7427\n",
      "Epoch 7/29, Train Loss: 0.5151, Train Acc: 0.7709, Val Loss: 0.5508, Val Acc: 0.7476\n",
      "Epoch 8/29, Train Loss: 0.5027, Train Acc: 0.7758, Val Loss: 0.5782, Val Acc: 0.7961\n",
      "Epoch 9/29, Train Loss: 0.5141, Train Acc: 0.7624, Val Loss: 0.5875, Val Acc: 0.7136\n",
      "Epoch 10/29, Train Loss: 0.4749, Train Acc: 0.7830, Val Loss: 1.0108, Val Acc: 0.7136\n",
      "Epoch 11/29, Train Loss: 0.4589, Train Acc: 0.7952, Val Loss: 1.0200, Val Acc: 0.7330\n",
      "Epoch 12/29, Train Loss: 0.4656, Train Acc: 0.7867, Val Loss: 0.9818, Val Acc: 0.7573\n",
      "Epoch 13/29, Train Loss: 0.4400, Train Acc: 0.8024, Val Loss: 1.0012, Val Acc: 0.7524\n",
      "Epoch 14/29, Train Loss: 0.4475, Train Acc: 0.7879, Val Loss: 1.0051, Val Acc: 0.7573\n",
      "Epoch 15/29, Train Loss: 0.4137, Train Acc: 0.8315, Val Loss: 1.0332, Val Acc: 0.7039\n",
      "Epoch 16/29, Train Loss: 0.3916, Train Acc: 0.8097, Val Loss: 1.0029, Val Acc: 0.7816\n",
      "Epoch 17/29, Train Loss: 0.3647, Train Acc: 0.8352, Val Loss: 1.0277, Val Acc: 0.7670\n",
      "Epoch 18/29, Train Loss: 0.4320, Train Acc: 0.8182, Val Loss: 1.0091, Val Acc: 0.7621\n",
      "Epoch 19/29, Train Loss: 0.3995, Train Acc: 0.8242, Val Loss: 0.9976, Val Acc: 0.7621\n",
      "Epoch 20/29, Train Loss: 0.3626, Train Acc: 0.8424, Val Loss: 1.0022, Val Acc: 0.7670\n",
      "Epoch 21/29, Train Loss: 0.3483, Train Acc: 0.8339, Val Loss: 1.0333, Val Acc: 0.7573\n",
      "Epoch 22/29, Train Loss: 0.3413, Train Acc: 0.8558, Val Loss: 1.0348, Val Acc: 0.7621\n",
      "Epoch 23/29, Train Loss: 0.3355, Train Acc: 0.8618, Val Loss: 1.0451, Val Acc: 0.7670\n",
      "Epoch 24/29, Train Loss: 0.3638, Train Acc: 0.8461, Val Loss: 1.0348, Val Acc: 0.7718\n",
      "Epoch 25/29, Train Loss: 0.3338, Train Acc: 0.8570, Val Loss: 1.0371, Val Acc: 0.7767\n",
      "Epoch 26/29, Train Loss: 0.3459, Train Acc: 0.8570, Val Loss: 1.0352, Val Acc: 0.7621\n",
      "Epoch 27/29, Train Loss: 0.3245, Train Acc: 0.8655, Val Loss: 1.0362, Val Acc: 0.7767\n",
      "Epoch 28/29, Train Loss: 0.3382, Train Acc: 0.8582, Val Loss: 1.0340, Val Acc: 0.7767\n",
      "Epoch 29/29, Train Loss: 0.3249, Train Acc: 0.8533, Val Loss: 1.0307, Val Acc: 0.7767\n",
      "Fold 3 Balanced Accuracy: 0.7736742424242424\n",
      "Fold 4/5\n",
      "Epoch 0/29, Train Loss: 0.7408, Train Acc: 0.4655, Val Loss: 0.6851, Val Acc: 0.5388\n",
      "Epoch 1/29, Train Loss: 0.7021, Train Acc: 0.5382, Val Loss: 0.6459, Val Acc: 0.6699\n",
      "Epoch 2/29, Train Loss: 0.6566, Train Acc: 0.6194, Val Loss: 0.5866, Val Acc: 0.7087\n",
      "Epoch 3/29, Train Loss: 0.5907, Train Acc: 0.6958, Val Loss: 0.5461, Val Acc: 0.7379\n",
      "Epoch 4/29, Train Loss: 0.5437, Train Acc: 0.7358, Val Loss: 0.5010, Val Acc: 0.7330\n",
      "Epoch 5/29, Train Loss: 0.5640, Train Acc: 0.7309, Val Loss: 0.5096, Val Acc: 0.7476\n",
      "Epoch 6/29, Train Loss: 0.5261, Train Acc: 0.7673, Val Loss: 0.4873, Val Acc: 0.7330\n",
      "Epoch 7/29, Train Loss: 0.5241, Train Acc: 0.7394, Val Loss: 0.4790, Val Acc: 0.7573\n",
      "Epoch 8/29, Train Loss: 0.4640, Train Acc: 0.7903, Val Loss: 0.5007, Val Acc: 0.7573\n",
      "Epoch 9/29, Train Loss: 0.4791, Train Acc: 0.7758, Val Loss: 0.4841, Val Acc: 0.7573\n",
      "Epoch 10/29, Train Loss: 0.5063, Train Acc: 0.7588, Val Loss: 0.4804, Val Acc: 0.7427\n",
      "Epoch 11/29, Train Loss: 0.4761, Train Acc: 0.7976, Val Loss: 0.4893, Val Acc: 0.7330\n",
      "Epoch 12/29, Train Loss: 0.4647, Train Acc: 0.7794, Val Loss: 0.4680, Val Acc: 0.7718\n",
      "Epoch 13/29, Train Loss: 0.4300, Train Acc: 0.8036, Val Loss: 0.4833, Val Acc: 0.7718\n",
      "Epoch 14/29, Train Loss: 0.4424, Train Acc: 0.7758, Val Loss: 0.4918, Val Acc: 0.7621\n",
      "Epoch 15/29, Train Loss: 0.4438, Train Acc: 0.7964, Val Loss: 0.4672, Val Acc: 0.7379\n",
      "Epoch 16/29, Train Loss: 0.4222, Train Acc: 0.8048, Val Loss: 0.4936, Val Acc: 0.7476\n",
      "Epoch 17/29, Train Loss: 0.4213, Train Acc: 0.8061, Val Loss: 0.5051, Val Acc: 0.7524\n",
      "Epoch 18/29, Train Loss: 0.4124, Train Acc: 0.8024, Val Loss: 0.4613, Val Acc: 0.7816\n",
      "Epoch 19/29, Train Loss: 0.4162, Train Acc: 0.8170, Val Loss: 0.4580, Val Acc: 0.7961\n",
      "Epoch 20/29, Train Loss: 0.3731, Train Acc: 0.8364, Val Loss: 0.4730, Val Acc: 0.7718\n",
      "Epoch 21/29, Train Loss: 0.3582, Train Acc: 0.8618, Val Loss: 0.4677, Val Acc: 0.7767\n",
      "Epoch 22/29, Train Loss: 0.3617, Train Acc: 0.8291, Val Loss: 0.4744, Val Acc: 0.7670\n",
      "Epoch 23/29, Train Loss: 0.3525, Train Acc: 0.8473, Val Loss: 0.4786, Val Acc: 0.7573\n",
      "Epoch 24/29, Train Loss: 0.3291, Train Acc: 0.8545, Val Loss: 0.4774, Val Acc: 0.7670\n",
      "Epoch 25/29, Train Loss: 0.3729, Train Acc: 0.8400, Val Loss: 0.4741, Val Acc: 0.7816\n",
      "Epoch 26/29, Train Loss: 0.3513, Train Acc: 0.8436, Val Loss: 0.4761, Val Acc: 0.7816\n",
      "Epoch 27/29, Train Loss: 0.3306, Train Acc: 0.8630, Val Loss: 0.4748, Val Acc: 0.7864\n",
      "Epoch 28/29, Train Loss: 0.3334, Train Acc: 0.8448, Val Loss: 0.4729, Val Acc: 0.7767\n",
      "Epoch 29/29, Train Loss: 0.3366, Train Acc: 0.8533, Val Loss: 0.4776, Val Acc: 0.7718\n",
      "Fold 4 Balanced Accuracy: 0.7678030303030303\n",
      "Fold 5/5\n",
      "Epoch 0/29, Train Loss: 0.7213, Train Acc: 0.4994, Val Loss: 0.6809, Val Acc: 0.6019\n",
      "Epoch 1/29, Train Loss: 0.6994, Train Acc: 0.5285, Val Loss: 0.6487, Val Acc: 0.6845\n",
      "Epoch 2/29, Train Loss: 0.6535, Train Acc: 0.6279, Val Loss: 0.6043, Val Acc: 0.6990\n",
      "Epoch 3/29, Train Loss: 0.5955, Train Acc: 0.6848, Val Loss: 0.5796, Val Acc: 0.6942\n",
      "Epoch 4/29, Train Loss: 0.5704, Train Acc: 0.7224, Val Loss: 0.5583, Val Acc: 0.7136\n",
      "Epoch 5/29, Train Loss: 0.5124, Train Acc: 0.7321, Val Loss: 0.5307, Val Acc: 0.7379\n",
      "Epoch 6/29, Train Loss: 0.4984, Train Acc: 0.7709, Val Loss: 0.5874, Val Acc: 0.7476\n",
      "Epoch 7/29, Train Loss: 0.4915, Train Acc: 0.7673, Val Loss: 0.5244, Val Acc: 0.7427\n",
      "Epoch 8/29, Train Loss: 0.4819, Train Acc: 0.7479, Val Loss: 0.5487, Val Acc: 0.7427\n",
      "Epoch 9/29, Train Loss: 0.4826, Train Acc: 0.7879, Val Loss: 0.5353, Val Acc: 0.7573\n",
      "Epoch 10/29, Train Loss: 0.4566, Train Acc: 0.7915, Val Loss: 0.5651, Val Acc: 0.7330\n",
      "Epoch 11/29, Train Loss: 0.4696, Train Acc: 0.7927, Val Loss: 0.5452, Val Acc: 0.7476\n",
      "Epoch 12/29, Train Loss: 0.4395, Train Acc: 0.8073, Val Loss: 0.5258, Val Acc: 0.7379\n",
      "Epoch 13/29, Train Loss: 0.4220, Train Acc: 0.8036, Val Loss: 0.5282, Val Acc: 0.7184\n",
      "Epoch 14/29, Train Loss: 0.4310, Train Acc: 0.7903, Val Loss: 0.5692, Val Acc: 0.7330\n",
      "Epoch 15/29, Train Loss: 0.4275, Train Acc: 0.8012, Val Loss: 0.5553, Val Acc: 0.7379\n",
      "Epoch 16/29, Train Loss: 0.4066, Train Acc: 0.8073, Val Loss: 0.5563, Val Acc: 0.7184\n",
      "Epoch 17/29, Train Loss: 0.3576, Train Acc: 0.8267, Val Loss: 0.5725, Val Acc: 0.7476\n",
      "Epoch 18/29, Train Loss: 0.3938, Train Acc: 0.8145, Val Loss: 0.5922, Val Acc: 0.7427\n",
      "Epoch 19/29, Train Loss: 0.3892, Train Acc: 0.8279, Val Loss: 0.5560, Val Acc: 0.7476\n",
      "Epoch 20/29, Train Loss: 0.3606, Train Acc: 0.8352, Val Loss: 0.5605, Val Acc: 0.7427\n",
      "Epoch 21/29, Train Loss: 0.3390, Train Acc: 0.8594, Val Loss: 0.5660, Val Acc: 0.7379\n",
      "Epoch 22/29, Train Loss: 0.3817, Train Acc: 0.8412, Val Loss: 0.5628, Val Acc: 0.7427\n",
      "Epoch 23/29, Train Loss: 0.3450, Train Acc: 0.8339, Val Loss: 0.5815, Val Acc: 0.7427\n",
      "Epoch 24/29, Train Loss: 0.3343, Train Acc: 0.8533, Val Loss: 0.5700, Val Acc: 0.7379\n",
      "Epoch 25/29, Train Loss: 0.2953, Train Acc: 0.8776, Val Loss: 0.5694, Val Acc: 0.7379\n",
      "Epoch 26/29, Train Loss: 0.3240, Train Acc: 0.8739, Val Loss: 0.5758, Val Acc: 0.7330\n",
      "Epoch 27/29, Train Loss: 0.3191, Train Acc: 0.8776, Val Loss: 0.5932, Val Acc: 0.7330\n",
      "Epoch 28/29, Train Loss: 0.3049, Train Acc: 0.8679, Val Loss: 0.6012, Val Acc: 0.7233\n",
      "Epoch 29/29, Train Loss: 0.3246, Train Acc: 0.8545, Val Loss: 0.5990, Val Acc: 0.7184\n",
      "Fold 5 Balanced Accuracy: 0.7184659090909091\n",
      "Best Balanced Accuracy from Cross-Validation: 0.7736742424242424\n"
     ]
    }
   ],
   "source": [
    "# Define a deeper neural network model with batch normalization and dropout\n",
    "class DeepNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DeepNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.bn4 = nn.BatchNorm1d(32)\n",
    "        self.fc5 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc5(x))\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_dim = X_preprocessed.shape[1]\n",
    "model = DeepNN(input_dim).cuda()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# Function to train the model with cross-validation\n",
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs=30, fold=0):\n",
    "    best_acc = 0.0\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=num_epochs)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.cuda(), y_batch.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            running_loss += loss.item() * X_batch.size(0)\n",
    "            correct_train += (torch.round(outputs) == y_batch.unsqueeze(1)).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = correct_train / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_acc)\n",
    "        \n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct_val = 0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        \n",
    "        for X_batch, y_batch in valid_loader:\n",
    "            X_batch, y_batch = X_batch.cuda(), y_batch.cuda()\n",
    "            with torch.no_grad():\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch.unsqueeze(1))\n",
    "                running_loss += loss.item() * X_batch.size(0)\n",
    "                preds = torch.round(outputs)\n",
    "                correct_val += (preds.squeeze() == y_batch).sum().item()\n",
    "                all_labels.extend(y_batch.cpu().numpy())\n",
    "                all_preds.extend(preds.squeeze().cpu().numpy())\n",
    "        \n",
    "        val_loss = running_loss / len(valid_loader.dataset)\n",
    "        val_acc = correct_val / len(valid_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}, Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = model.state_dict()\n",
    "            torch.save(best_model_wts, f's1best_model_fold_{fold}.pt')\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, train_losses, val_losses, train_accuracies, val_accuracies, all_labels, all_preds\n",
    "\n",
    "# Function for cross-validation training\n",
    "def cross_val_train(model, X, y, n_splits=5, num_epochs=30):\n",
    "    best_acc = 0.0\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    fold_results = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "        \n",
    "        X_train_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
    "        X_valid_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train_fold, dtype=torch.float32)\n",
    "        y_valid_tensor = torch.tensor(y_val_fold, dtype=torch.float32)\n",
    "\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        valid_dataset = TensorDataset(X_valid_tensor, y_valid_tensor)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "        \n",
    "        model = DeepNN(input_dim).cuda()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "        \n",
    "        model, train_losses, val_losses, train_accuracies, val_accuracies, val_labels, val_preds = train_model(\n",
    "            model, train_loader, valid_loader, criterion, optimizer, num_epochs, fold)\n",
    "        \n",
    "        balanced_acc = balanced_accuracy_score(val_labels, val_preds)\n",
    "        print(f\"Fold {fold + 1} Balanced Accuracy: {balanced_acc}\")\n",
    "        \n",
    "        fold_results.append((train_losses, val_losses, train_accuracies, val_accuracies))\n",
    "        \n",
    "        if balanced_acc > best_acc:\n",
    "            best_acc = balanced_acc\n",
    "    \n",
    "    return model, best_acc, fold_results\n",
    "\n",
    "# Train the model with cross-validation\n",
    "trained_model, best_acc, fold_results = cross_val_train(model, X_preprocessed, y.values, num_epochs=30)\n",
    "print(f\"Best Balanced Accuracy from Cross-Validation: {best_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "653bc08f-2ffb-43e7-933c-39d909dd2f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.8918741808650066\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.93      0.90       109\n",
      "         1.0       0.91      0.86      0.88        98\n",
      "\n",
      "    accuracy                           0.89       207\n",
      "   macro avg       0.90      0.89      0.89       207\n",
      "weighted avg       0.89      0.89      0.89       207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_preprocessed, y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert validation data to PyTorch tensors\n",
    "X_valid_tensor = torch.tensor(X_valid, dtype=torch.float32).cuda()\n",
    "y_valid_tensor = torch.tensor(y_valid.values, dtype=torch.float32).cuda()\n",
    "\n",
    "# Load the best model\n",
    "best_model_path = 's1best_model_fold_0.pt'  # Adjust according to the best fold\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "# Predict on validation data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_preds = model(X_valid_tensor)\n",
    "    val_preds = torch.round(val_preds).cpu().numpy().flatten()\n",
    "\n",
    "# Evaluate the model\n",
    "balanced_acc = balanced_accuracy_score(y_valid_tensor.cpu().numpy(), val_preds)\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_valid_tensor.cpu().numpy(), val_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Reds', xticklabels=['MILD', 'SEVERE'], yticklabels=['MILD', 'SEVERE'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_valid_tensor.cpu().numpy(), val_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a44abcac-4c41-4745-84b4-a7f1ed47f719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file for Category 1 created successfully!\n",
      "    Id Prognosis\n",
      "0  657      MILD\n",
      "1  212      MILD\n",
      "2  108      MILD\n",
      "3  666    SEVERE\n",
      "4  861      MILD\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the test data\n",
    "X_test_preprocessed = preprocessor.transform(test_df.drop(columns=['Image']))\n",
    "X_test_tensor = torch.tensor(X_test_preprocessed, dtype=torch.float32).cuda()\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "# Predict on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_preds = model(X_test_tensor)\n",
    "    test_preds = torch.round(test_preds).cpu().numpy().flatten()  # Ensure predictions are 1-dimensional\n",
    "\n",
    "# Create a submission dataframe\n",
    "submission1 = pd.DataFrame({'Id': test_df['Image'], 'Prognosis': test_preds})\n",
    "submission1['Prognosis'] = submission1['Prognosis'].map({0.0: 'MILD', 1.0: 'SEVERE'})\n",
    "submission1.to_csv('mldl_competition4_Alargum_submission1.csv', index=False)\n",
    "\n",
    "print(\"Submission file for Category 1 created successfully!\")\n",
    "\n",
    "print(submission1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f26e2-fc98-49f4-805d-f3076e6a9284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
